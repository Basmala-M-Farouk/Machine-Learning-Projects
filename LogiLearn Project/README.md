# âš™ï¸ OptiLogiX  
**Optimizer Strategies for Logistic Regression in Binary Classification**

## ğŸ“˜ Overview

This project implements **Logistic Regression from scratch** in NumPy and benchmarks three popular optimization techniques:

- âœ… Gradient Descent (GD)  
- ğŸ”„ Stochastic Gradient Descent (SGD)  
- ğŸ”€ Mini-Batch Gradient Descent  

The goal is to compare their performance in terms of:
- Convergence speed
- Classification metrics (Accuracy, Precision, Recall, F1-score)
- Training stability

---

## ğŸ“‚ Dataset

The dataset is synthetically generated using `sklearn.datasets.make_classification()` to simulate a real-world binary classification scenario with:
- 10,000 samples
- 30 features (15 informative)

---

## ğŸ“Š Evaluation Metrics

Each optimizer is evaluated using:
- ğŸ”¹ Confusion Matrix
- ğŸ”¹ Accuracy
- ğŸ”¹ Precision
- ğŸ”¹ Recall
- ğŸ”¹ F1-Score

---

## ğŸš€ How to Run

```bash
1. Clone the repo or open the notebook in Google Colab
2. Run all cells in order

